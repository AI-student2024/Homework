{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17de82c0",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "#### 扩展 Demo：实现生物、计算机和汉语言文学老师 PromptTemplates 及对应 Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf8c391-9225-4e66-ad4d-d689b53a0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b5061c-391e-4762-91c7-73b57f4ab501",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"你是一位非常聪明的物理教授。\n",
    "你擅长以简洁易懂的方式回答关于物理的问题。\n",
    "当你不知道某个问题的答案时，你会坦诚承认。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"你是一位很棒的数学家。你擅长回答数学问题。\n",
    "之所以如此出色，是因为你能够将难题分解成各个组成部分，\n",
    "先回答这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"你是一位经验丰富的生物学家。你特别擅长解答有关生物学的问题。\n",
    "你之所以能够出色地回答问题，是因为你对生物学的各个分支都有深入的了解，\n",
    "包括细胞生物学、遗传学、生态学和进化论。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "computer_template = \"\"\"你是一位杰出的计算机科学家。你在处理计算机科学相关问题方面非常专业。\n",
    "你能够出色完成任务的秘密在于你对算法、数据结构、编程语言和系统架构的深刻理解。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "chinese_template = \"\"\"你是一位才华横溢的汉语言文学老师。你对古典文学和现代文学都有着深厚的理解。\n",
    "你能够精彩地回答有关文学的问题，这得益于你对文学作品的深入分析，\n",
    "以及你对诗歌、散文、小说等各种文学形式的广泛知识。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef1db6e-3da4-4f9b-9707-0f30aa293dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"物理\",\n",
    "        \"description\": \"适用于回答物理问题\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"数学\",\n",
    "        \"description\": \"适用于回答数学问题\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"生物\",\n",
    "        \"description\": \"适用于回答生物学问题\",\n",
    "        \"prompt_template\": biology_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"计算机\",\n",
    "        \"description\": \"适用于回答计算机问题\",\n",
    "        \"prompt_template\": computer_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"汉语言文学\",\n",
    "        \"description\": \"适用于回答汉语言文学问题\",\n",
    "        \"prompt_template\": chinese_template,\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3983cafe-c2d5-4951-b779-88d844594777",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8be9f0-1ac2-4ded-8950-6403cfa40004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的目标链字典，用于存放根据prompt_infos生成的LLMChain。\n",
    "destination_chains = {}\n",
    "\n",
    "# 遍历prompt_infos列表，为每个信息创建一个LLMChain。\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]  # 提取名称\n",
    "    prompt_template = p_info[\"prompt_template\"]  # 提取模板\n",
    "    # 创建PromptTemplate对象\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    # 使用上述模板和llm对象创建LLMChain对象\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # 将新创建的chain对象添加到destination_chains字典中\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# 创建一个默认的ConversationChain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b24aa04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'物理': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='你是一位非常聪明的物理教授。\\n你擅长以简洁易懂的方式回答关于物理的问题。\\n当你不知道某个问题的答案时，你会坦诚承认。\\n\\n这是一个问题：\\n{input}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001C17FF132D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C10E025910>, openai_api_key=SecretStr('**********'), openai_proxy='')), '数学': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='你是一位很棒的数学家。你擅长回答数学问题。\\n之所以如此出色，是因为你能够将难题分解成各个组成部分，\\n先回答这些组成部分，然后再将它们整合起来回答更广泛的问题。\\n\\n这是一个问题：\\n{input}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001C17FF132D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C10E025910>, openai_api_key=SecretStr('**********'), openai_proxy='')), '生物': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='你是一位经验丰富的生物学家。你特别擅长解答有关生物学的问题。\\n你之所以能够出色地回答问题，是因为你对生物学的各个分支都有深入的了解，\\n包括细胞生物学、遗传学、生态学和进化论。\\n\\n这是一个问题：\\n{input}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001C17FF132D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C10E025910>, openai_api_key=SecretStr('**********'), openai_proxy='')), '计算机': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='你是一位杰出的计算机科学家。你在处理计算机科学相关问题方面非常专业。\\n你能够出色完成任务的秘密在于你对算法、数据结构、编程语言和系统架构的深刻理解。\\n\\n这是一个问题：\\n{input}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001C17FF132D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C10E025910>, openai_api_key=SecretStr('**********'), openai_proxy='')), '汉语言文学': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='你是一位才华横溢的汉语言文学老师。你对古典文学和现代文学都有着深厚的理解。\\n你能够精彩地回答有关文学的问题，这得益于你对文学作品的深入分析，\\n以及你对诗歌、散文、小说等各种文学形式的广泛知识。\\n\\n这是一个问题：\\n{input}'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001C17FF132D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C10E025910>, openai_api_key=SecretStr('**********'), openai_proxy=''))}\n"
     ]
    }
   ],
   "source": [
    "print(destination_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae77b13a-2077-4e80-83f9-a2b1d8398461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.chains.conversation.base.ConversationChain"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa4a82-2d96-4124-8896-4e11e5d5c8e9",
   "metadata": {},
   "source": [
    "### 使用 LLMRouterChain 实现条件判断调用\n",
    "\n",
    "这段代码定义了一个chain对象（LLMRouterChain），该对象首先使用router_chain来决定哪个destination_chain应该被执行，如果没有合适的目标链，则默认使用default_chain。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c196e6c-e767-4d4f-8327-50ead641bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ada86e-e430-412c-828d-b053b630f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从prompt_infos中提取目标信息并将其转化为字符串列表\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "# 使用join方法将列表转化为字符串，每个元素之间用换行符分隔\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "# 根据MULTI_PROMPT_ROUTER_TEMPLATE格式化字符串和destinations_str创建路由模板\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "# 创建路由的PromptTemplate\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "# 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1013dc-ae1f-468d-96b3-4babe0d50d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['物理: 适用于回答物理问题', '数学: 适用于回答数学问题', '生物: 适用于回答生物学问题', '计算机: 适用于回答计算机问题', '汉语言文学: 适用于回答汉语言文学问题']\n"
     ]
    }
   ],
   "source": [
    "print(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a85ef126-aca1-40c2-8e01-d15af5500785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物学问题\n",
      "计算机: 适用于回答计算机问题\n",
      "汉语言文学: 适用于回答汉语言文学问题\n"
     ]
    }
   ],
   "source": [
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "667e5fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=True llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['input'], output_parser=RouterOutputParser(), template='Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{{\\n    \"destination\": string \\\\ name of the prompt to use or \"DEFAULT\"\\n    \"next_inputs\": string \\\\ a potentially modified version of the original input\\n}}\\n```\\n\\nREMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\\nREMEMBER: \"next_inputs\" can just be the original input if you don\\'t think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\n物理: 适用于回答物理问题\\n数学: 适用于回答数学问题\\n生物: 适用于回答生物学问题\\n计算机: 适用于回答计算机问题\\n汉语言文学: 适用于回答汉语言文学问题\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT (must include ```json at the start of the response) >>\\n<< OUTPUT (must end with ```) >>\\n'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001C17FF132D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C10E025910>, openai_api_key=SecretStr('**********'), openai_proxy=''))\n"
     ]
    }
   ],
   "source": [
    "print(router_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db81fcb-704a-4250-a6b5-210e4be77af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f882244c-1fa6-4d74-a44c-578c9fb25e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物学问题\n",
      "计算机: 适用于回答计算机问题\n",
      "汉语言文学: 适用于回答汉语言文学问题\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a482e4-5757-4295-a3d8-c3fdd1d4abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建MultiPromptChain对象，其中包含了路由链，目标链和默认链。\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128bb7a0-b176-4b14-835e-8aaa723ab441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anacondaInstall\\envs\\transformers\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "计算机: {'input': 'GPU是什么?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "GPU是图形处理器，也称为显卡，是一种专门用于处理图形和图像相关计算的硬件设备。它可以加速计算机图形渲染、视频编码、深度学习等任务，相较于传统的中央处理器（CPU），GPU具有更强大的计算能力和并行处理能力。它通常被使用在游戏、设计、科学计算等领域。\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"GPU是什么?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd869807-9cec-4bb2-9104-ecc4efce9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "数学: {'input': '大于40的第一个质数是多少，使得这个质数加一能被3整除？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "答案：43。因为43是大于40的最小质数，43+1=44，44能被3整除。\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.run(\n",
    "        \"大于40的第一个质数是多少，使得这个质数加一能被3整除？\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cf5c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "汉语言文学: {'input': '矛盾文学奖是哪一年设置的?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "矛盾文学奖是1981年在中国由中国作家协会设立的文学奖项。它旨在表彰在社会主义现实主义文学创作中，具有独立思考、反映矛盾和冲突的作品。自1981年至今，矛盾文学奖已经评选出多位优秀作家，为中国文学界做出了重要贡献。\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"矛盾文学奖是哪一年设置的?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fef3ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "汉语言文学: {'input': '诗书礼易乐春秋是指什么?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "诗书礼易乐春秋是中国古代一部重要的典籍，也是儒家经典之一。它是由儒家思想家孔子及其弟子编纂的一部政治、道德和文化方面的著作，内容涉及诗、书、礼、易、乐等方面的知识。它强调的是君子应该具备的品德和修养，以及如何治理国家和社会。它被认为是传统文化的重要组成部分，对中国古代的政治、社会和文化产生了深远的影响。\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"诗书礼易乐春秋是指什么?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "生物: {'input': '大象的鼻子有什么作用'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "？\n",
      "\n",
      "大象的鼻子是一种非常重要的器官，它在大象的生活中发挥着多种作用。首先，大象的鼻子是它们的主要呼吸器官，它们可以通过鼻子吸入氧气并排出二氧化碳。此外，大象的鼻子也是它们的嗅觉器官，它们可以借助鼻子来感知周围的气味，包括食物、水源、同类和潜在的危险。大象的鼻子还有助于它们在炎热的天气中保持体温平衡，因为它们可以通过鼻子排出热量。最后，大象的鼻子还能用来触摸和抓取物体，帮助它们在采食和社交\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"大象的鼻子有什么作用\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad5dcb2-48c0-4d0f-b6cc-09ebcbdce75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd37e004-bb24-4929-992c-34407593d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "物理: {'input': '黑洞是什么？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "黑洞是一种极为密集的天体，它的引力极强，甚至连光都无法逃脱。它的形成是由于某颗恒星燃尽所有的燃料，塌缩成一个无限小、无限密集的点，这就是我们所说的黑洞。它的引力场非常强大，可以吸引周围的物质，甚至连光也无法逃脱，因此我们无法直接观测到它。但是，科学家通过观测周围的物质运动和引力效应，可以推断出黑洞的存在。黑洞是宇宙中非常神秘和有趣的物体，它们的研究也是物理学家们持续探索的重要课题。\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"黑洞是什么？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51119ed-025f-48d7-ad81-cd9cdab7090f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
